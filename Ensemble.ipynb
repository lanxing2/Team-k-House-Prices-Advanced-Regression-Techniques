{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Columns: 263 entries, LotFrontage to SaleCondition__Partial\n",
      "dtypes: float64(231), int64(32)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "base_path='D:/kaggle/regression/'\n",
    "all_data=DataFrame.from_csv(base_path+'cleaned_train.csv',index_col='Id')\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Columns: 262 entries, LotFrontage to SaleCondition__Partial\n",
      "dtypes: float64(231), int64(31)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "all_id=all_data.index\n",
    "all_y=all_data['SalePrice']\n",
    "all_x=all_data.drop(['SalePrice'],axis=1)\n",
    "all_x.info()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(all_x, all_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_log_error(predict,reality):\n",
    "    predict_log=np.log(predict)\n",
    "    reality_log=np.log(reality)\n",
    "    mse=mean_squared_error(reality_log, predict_log)\n",
    "    rmse=np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# A function to train several models for the train/test pair for one fold\n",
    "# How to tune parameters is out of scope of this script, check out sklearn's GridSearchCV or RandomizedSearchCV\n",
    "def one_fold(train_x,train_y,test_x,test_y):\n",
    "    # Report shape\n",
    "    print \"Training set has shape: \",X_train.shape\n",
    "    print \"Test set has shape: \",X_test.shape\n",
    "\n",
    "    # Random forest with mse, auto-tuned\n",
    "    print \"Random forest with mse\"\n",
    "    rf0 = RandomForestRegressor(criterion='mse', n_estimators=126,max_features=0.5,max_depth=10,random_state=42)\n",
    "    print \"Fitting random forest with mse\"\n",
    "    rf0.fit(train_x, train_y)\n",
    "    print 'Predicting on test set'\n",
    "    rf0_result=rf0.predict(test_x)\n",
    "    print('RF Auto RMSE {score}'.format(score=rmse_log_error(test_y, rf0_result)))\n",
    "    \n",
    "    # Random forest with mse, hand-tuned\n",
    "    print \"Random forest with mse\"\n",
    "    rf1 = RandomForestRegressor(criterion='mse', n_estimators=250,max_features=0.21,max_depth=31,random_state=42)\n",
    "    print \"Fitting random forest with mse\"\n",
    "    rf1.fit(train_x, train_y)\n",
    "    print 'Predicting on test set'\n",
    "    rf1_result=rf1.predict(test_x)\n",
    "    print('RF Manual RMSE {score}'.format(score=rmse_log_error(test_y, rf1_result)))\n",
    "    \n",
    "    # Extra tree regressor\n",
    "    print \"ExtraTreesRegressor\"\n",
    "    et = ExtraTreesRegressor(criterion='mse', n_estimators=180,max_features=0.2,max_depth=28,n_jobs=-1,random_state=42)\n",
    "    print \"Fitting extra trees regressor with mse\"\n",
    "    et.fit(train_x,train_y)\n",
    "    print 'Predicting on test set'\n",
    "    et_result=et.predict(test_x)   \n",
    "    print('ET RMSE {score}'.format(score=rmse_log_error(test_y, et_result)))\n",
    "    \n",
    "    # Adaboost linear\n",
    "    print 'Adaboost linear'\n",
    "    ad0=AdaBoostRegressor(loss='linear',learning_rate=0.2,n_estimators=210,random_state=42)\n",
    "    print 'Fitting adaboost linear'\n",
    "    ad0.fit(train_x,train_y)\n",
    "    print 'Predicting on test set'\n",
    "    ad_result=ad0.predict(test_x)  \n",
    "    print('Adaboost Linear RMSE {score}'.format(score=rmse_log_error(test_y, ad_result)))\n",
    "    \n",
    "    # Adaboost square\n",
    "    print 'Adaboost square'\n",
    "    ad1=AdaBoostRegressor(loss='square',learning_rate=0.526,n_estimators=410,random_state=42)\n",
    "    print 'Fitting adaboost linear'\n",
    "    ad1.fit(train_x,train_y)\n",
    "    print 'Predicting on test set'\n",
    "    ad1_result=ad1.predict(test_x)  \n",
    "    print('Adaboost Square RMSE {score}'.format(score=rmse_log_error(test_y, ad1_result)))\n",
    "    \n",
    "    # Adaboost exp\n",
    "    print 'Adaboost exponential'\n",
    "    ad2=AdaBoostRegressor(loss='exponential',learning_rate=0.342,n_estimators=158,random_state=42)\n",
    "    print 'Fitting adaboost linear'\n",
    "    ad2.fit(train_x,train_y)\n",
    "    print 'Predicting on test set'\n",
    "    ad2_result=ad2.predict(test_x)  \n",
    "    print('Adaboost Exponential RMSE {score}'.format(score=rmse_log_error(test_y, ad2_result)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    regressors={\n",
    "        'rf0':rf0,\n",
    "        'rf1':rf1,\n",
    "        'et':et,\n",
    "        'ad0':ad0,\n",
    "        'ad1':ad1,\n",
    "        'ad2':ad2\n",
    "    }\n",
    "    \n",
    "    return regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.135227049228\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.13444192827\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.137454863367\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.189990058727\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.21154859265\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.188599456703\n",
      "Iteration  1\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.142306752728\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.14237668758\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.137500656406\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.197530934996\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.21496975191\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.192637744912\n",
      "Iteration  2\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.146889773904\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.143497242575\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.143048130957\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.199314363787\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.211952115602\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.193736561073\n",
      "Iteration  3\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.127933958239\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.125454010836\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.119227310044\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.172620926058\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.178939088457\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.172516100569\n",
      "Iteration  4\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.125571663831\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.123246339822\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.122988987679\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.177031212304\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.200331609214\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.176109691123\n",
      "Iteration  5\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.138669022745\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.139273269901\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.145154124153\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.214949541108\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.240009420758\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.209556212521\n",
      "Iteration  6\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.152082555566\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.149125177885\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.148307637778\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.200423605523\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.215866913402\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.19619271594\n",
      "Iteration  7\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.135005774781\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.136933844545\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.144433105116\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.183965294827\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.210123801917\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.187904852161\n",
      "Iteration  8\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.137421672527\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.135509218115\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.135090177667\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.176056888163\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.193888909625\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.176395773298\n",
      "Iteration  9\n",
      "Training set has shape:  (1168, 262)\n",
      "Test set has shape:  (292, 262)\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Auto RMSE 0.11050357834\n",
      "Random forest with mse\n",
      "Fitting random forest with mse\n",
      "Predicting on test set\n",
      "RF Manual RMSE 0.109549177153\n",
      "ExtraTreesRegressor\n",
      "Fitting extra trees regressor with mse\n",
      "Predicting on test set\n",
      "ET RMSE 0.118124635312\n",
      "Adaboost linear\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Linear RMSE 0.158740407016\n",
      "Adaboost square\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Square RMSE 0.183807379834\n",
      "Adaboost exponential\n",
      "Fitting adaboost linear\n",
      "Predicting on test set\n",
      "Adaboost Exponential RMSE 0.158319405855\n",
      "60  regressors trained\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regressors={}\n",
    "for i in range(10):\n",
    "    print 'Iteration ',i\n",
    "    X_train, X_test, y_train, y_test=train_test_split(all_x, all_y, test_size=0.2, random_state=i)\n",
    "    batch=one_fold(X_train, y_train, X_test, y_test)\n",
    "    regressors['rf_auto_'+str(i)]=batch['rf0']\n",
    "    regressors['rf_manual_'+str(i)]=batch['rf1']\n",
    "    regressors['ad_linear_'+str(i)]=batch['ad0']\n",
    "    regressors['ad_sqr_'+str(i)]=batch['ad1']\n",
    "    regressors['ad_exp_'+str(i)]=batch['ad2']\n",
    "    regressors['et_'+str(i)]=batch['et']\n",
    "    \n",
    "print len(regressors),' regressors trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This batch contains:  ['rf_auto_0', 'rf_manual_0', 'ad_linear_0', 'ad_sqr_0', 'ad_exp_0', 'et_0']\n",
      "End of iteration  0\n",
      "This batch contains:  ['rf_auto_1', 'rf_manual_1', 'ad_linear_1', 'ad_sqr_1', 'ad_exp_1', 'et_1']\n",
      "End of iteration  1\n",
      "This batch contains:  ['rf_auto_2', 'rf_manual_2', 'ad_linear_2', 'ad_sqr_2', 'ad_exp_2', 'et_2']\n",
      "End of iteration  2\n",
      "This batch contains:  ['rf_auto_3', 'rf_manual_3', 'ad_linear_3', 'ad_sqr_3', 'ad_exp_3', 'et_3']\n",
      "End of iteration  3\n",
      "This batch contains:  ['rf_auto_4', 'rf_manual_4', 'ad_linear_4', 'ad_sqr_4', 'ad_exp_4', 'et_4']\n",
      "End of iteration  4\n",
      "This batch contains:  ['rf_auto_5', 'rf_manual_5', 'ad_linear_5', 'ad_sqr_5', 'ad_exp_5', 'et_5']\n",
      "End of iteration  5\n",
      "This batch contains:  ['rf_auto_6', 'rf_manual_6', 'ad_linear_6', 'ad_sqr_6', 'ad_exp_6', 'et_6']\n",
      "End of iteration  6\n",
      "This batch contains:  ['rf_auto_7', 'rf_manual_7', 'ad_linear_7', 'ad_sqr_7', 'ad_exp_7', 'et_7']\n",
      "End of iteration  7\n",
      "This batch contains:  ['rf_auto_8', 'rf_manual_8', 'ad_linear_8', 'ad_sqr_8', 'ad_exp_8', 'et_8']\n",
      "End of iteration  8\n",
      "This batch contains:  ['rf_auto_9', 'rf_manual_9', 'ad_linear_9', 'ad_sqr_9', 'ad_exp_9', 'et_9']\n",
      "End of iteration  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_auto_0</th>\n",
       "      <th>rf_manual_0</th>\n",
       "      <th>ad_linear_0</th>\n",
       "      <th>ad_sqr_0</th>\n",
       "      <th>ad_exp_0</th>\n",
       "      <th>et_0</th>\n",
       "      <th>rf_auto_1</th>\n",
       "      <th>rf_manual_1</th>\n",
       "      <th>ad_linear_1</th>\n",
       "      <th>ad_sqr_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ad_linear_8</th>\n",
       "      <th>ad_sqr_8</th>\n",
       "      <th>ad_exp_8</th>\n",
       "      <th>et_8</th>\n",
       "      <th>rf_auto_9</th>\n",
       "      <th>rf_manual_9</th>\n",
       "      <th>ad_linear_9</th>\n",
       "      <th>ad_sqr_9</th>\n",
       "      <th>ad_exp_9</th>\n",
       "      <th>et_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>188002.585453</td>\n",
       "      <td>187791.331384</td>\n",
       "      <td>195266.722363</td>\n",
       "      <td>201233.099852</td>\n",
       "      <td>196788.682808</td>\n",
       "      <td>188936.059554</td>\n",
       "      <td>187273.952684</td>\n",
       "      <td>187491.113644</td>\n",
       "      <td>193822.065755</td>\n",
       "      <td>200361.402547</td>\n",
       "      <td>...</td>\n",
       "      <td>193804.506873</td>\n",
       "      <td>199424.947256</td>\n",
       "      <td>194502.868138</td>\n",
       "      <td>189802.831058</td>\n",
       "      <td>185139.883758</td>\n",
       "      <td>185022.188726</td>\n",
       "      <td>190843.354134</td>\n",
       "      <td>196316.120544</td>\n",
       "      <td>192367.778812</td>\n",
       "      <td>185116.864469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>76706.648014</td>\n",
       "      <td>76188.954908</td>\n",
       "      <td>72908.549084</td>\n",
       "      <td>72957.973637</td>\n",
       "      <td>73181.767297</td>\n",
       "      <td>82261.125305</td>\n",
       "      <td>73669.677542</td>\n",
       "      <td>73287.741160</td>\n",
       "      <td>72136.948184</td>\n",
       "      <td>74870.767073</td>\n",
       "      <td>...</td>\n",
       "      <td>75490.369424</td>\n",
       "      <td>75967.740887</td>\n",
       "      <td>75032.670615</td>\n",
       "      <td>82550.470979</td>\n",
       "      <td>67043.677536</td>\n",
       "      <td>65908.578581</td>\n",
       "      <td>67351.982059</td>\n",
       "      <td>65160.258217</td>\n",
       "      <td>68607.886735</td>\n",
       "      <td>64789.911952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>60959.015295</td>\n",
       "      <td>62591.344000</td>\n",
       "      <td>114596.085443</td>\n",
       "      <td>125644.113475</td>\n",
       "      <td>110208.456349</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>67167.337609</td>\n",
       "      <td>64581.128000</td>\n",
       "      <td>117515.840708</td>\n",
       "      <td>124986.055172</td>\n",
       "      <td>...</td>\n",
       "      <td>114372.103053</td>\n",
       "      <td>124821.079890</td>\n",
       "      <td>114787.089820</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>64129.129177</td>\n",
       "      <td>67693.236000</td>\n",
       "      <td>113042.623239</td>\n",
       "      <td>123830.006897</td>\n",
       "      <td>112580.648438</td>\n",
       "      <td>70175.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>134132.633951</td>\n",
       "      <td>135204.709000</td>\n",
       "      <td>134325.302280</td>\n",
       "      <td>149490.239264</td>\n",
       "      <td>139015.174771</td>\n",
       "      <td>134206.808712</td>\n",
       "      <td>134980.873707</td>\n",
       "      <td>135451.285000</td>\n",
       "      <td>133961.657459</td>\n",
       "      <td>141367.551220</td>\n",
       "      <td>...</td>\n",
       "      <td>135453.094420</td>\n",
       "      <td>138202.860081</td>\n",
       "      <td>131767.183633</td>\n",
       "      <td>136645.676136</td>\n",
       "      <td>134647.950877</td>\n",
       "      <td>135123.249000</td>\n",
       "      <td>133053.419056</td>\n",
       "      <td>145071.227116</td>\n",
       "      <td>132600.791611</td>\n",
       "      <td>136282.020139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>174746.859796</td>\n",
       "      <td>174209.828000</td>\n",
       "      <td>178815.720286</td>\n",
       "      <td>181857.842105</td>\n",
       "      <td>179178.678965</td>\n",
       "      <td>172898.291667</td>\n",
       "      <td>175844.409418</td>\n",
       "      <td>174355.454000</td>\n",
       "      <td>176692.946040</td>\n",
       "      <td>185418.410658</td>\n",
       "      <td>...</td>\n",
       "      <td>176029.036036</td>\n",
       "      <td>182434.074836</td>\n",
       "      <td>178471.810695</td>\n",
       "      <td>173450.000000</td>\n",
       "      <td>173662.215906</td>\n",
       "      <td>174792.988000</td>\n",
       "      <td>175836.159938</td>\n",
       "      <td>180657.395869</td>\n",
       "      <td>177661.001697</td>\n",
       "      <td>175159.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>217726.730015</td>\n",
       "      <td>219500.746000</td>\n",
       "      <td>221293.194030</td>\n",
       "      <td>228820.571154</td>\n",
       "      <td>223441.432665</td>\n",
       "      <td>220626.041667</td>\n",
       "      <td>215140.438240</td>\n",
       "      <td>218815.529000</td>\n",
       "      <td>227461.507463</td>\n",
       "      <td>230828.850668</td>\n",
       "      <td>...</td>\n",
       "      <td>220857.370559</td>\n",
       "      <td>235911.010001</td>\n",
       "      <td>221433.558613</td>\n",
       "      <td>223225.000000</td>\n",
       "      <td>213624.623929</td>\n",
       "      <td>213798.715000</td>\n",
       "      <td>223628.511401</td>\n",
       "      <td>229565.041336</td>\n",
       "      <td>224038.515464</td>\n",
       "      <td>213897.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>666643.883929</td>\n",
       "      <td>654331.692000</td>\n",
       "      <td>657205.785047</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>655096.118012</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>631410.715552</td>\n",
       "      <td>620335.392000</td>\n",
       "      <td>660454.348315</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>723421.052632</td>\n",
       "      <td>751190.476190</td>\n",
       "      <td>705000.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>461935.073091</td>\n",
       "      <td>480568.748000</td>\n",
       "      <td>481307.733096</td>\n",
       "      <td>556776.669510</td>\n",
       "      <td>481882.334728</td>\n",
       "      <td>429208.138889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rf_auto_0    rf_manual_0    ad_linear_0       ad_sqr_0  \\\n",
       "count     292.000000     292.000000     292.000000     292.000000   \n",
       "mean   188002.585453  187791.331384  195266.722363  201233.099852   \n",
       "std     76706.648014   76188.954908   72908.549084   72957.973637   \n",
       "min     60959.015295   62591.344000  114596.085443  125644.113475   \n",
       "25%    134132.633951  135204.709000  134325.302280  149490.239264   \n",
       "50%    174746.859796  174209.828000  178815.720286  181857.842105   \n",
       "75%    217726.730015  219500.746000  221293.194030  228820.571154   \n",
       "max    666643.883929  654331.692000  657205.785047  755000.000000   \n",
       "\n",
       "            ad_exp_0           et_0      rf_auto_1    rf_manual_1  \\\n",
       "count     292.000000     292.000000     292.000000     292.000000   \n",
       "mean   196788.682808  188936.059554  187273.952684  187491.113644   \n",
       "std     73181.767297   82261.125305   73669.677542   73287.741160   \n",
       "min    110208.456349   60000.000000   67167.337609   64581.128000   \n",
       "25%    139015.174771  134206.808712  134980.873707  135451.285000   \n",
       "50%    179178.678965  172898.291667  175844.409418  174355.454000   \n",
       "75%    223441.432665  220626.041667  215140.438240  218815.529000   \n",
       "max    655096.118012  755000.000000  631410.715552  620335.392000   \n",
       "\n",
       "         ad_linear_1       ad_sqr_1      ...          ad_linear_8  \\\n",
       "count     292.000000     292.000000      ...           292.000000   \n",
       "mean   193822.065755  200361.402547      ...        193804.506873   \n",
       "std     72136.948184   74870.767073      ...         75490.369424   \n",
       "min    117515.840708  124986.055172      ...        114372.103053   \n",
       "25%    133961.657459  141367.551220      ...        135453.094420   \n",
       "50%    176692.946040  185418.410658      ...        176029.036036   \n",
       "75%    227461.507463  230828.850668      ...        220857.370559   \n",
       "max    660454.348315  755000.000000      ...        723421.052632   \n",
       "\n",
       "            ad_sqr_8       ad_exp_8           et_8      rf_auto_9  \\\n",
       "count     292.000000     292.000000     292.000000     292.000000   \n",
       "mean   199424.947256  194502.868138  189802.831058  185139.883758   \n",
       "std     75967.740887   75032.670615   82550.470979   67043.677536   \n",
       "min    124821.079890  114787.089820   60000.000000   64129.129177   \n",
       "25%    138202.860081  131767.183633  136645.676136  134647.950877   \n",
       "50%    182434.074836  178471.810695  173450.000000  173662.215906   \n",
       "75%    235911.010001  221433.558613  223225.000000  213624.623929   \n",
       "max    751190.476190  705000.000000  755000.000000  461935.073091   \n",
       "\n",
       "         rf_manual_9    ad_linear_9       ad_sqr_9       ad_exp_9  \\\n",
       "count     292.000000     292.000000     292.000000     292.000000   \n",
       "mean   185022.188726  190843.354134  196316.120544  192367.778812   \n",
       "std     65908.578581   67351.982059   65160.258217   68607.886735   \n",
       "min     67693.236000  113042.623239  123830.006897  112580.648438   \n",
       "25%    135123.249000  133053.419056  145071.227116  132600.791611   \n",
       "50%    174792.988000  175836.159938  180657.395869  177661.001697   \n",
       "75%    213798.715000  223628.511401  229565.041336  224038.515464   \n",
       "max    480568.748000  481307.733096  556776.669510  481882.334728   \n",
       "\n",
       "                et_9  \n",
       "count     292.000000  \n",
       "mean   185116.864469  \n",
       "std     64789.911952  \n",
       "min     70175.361111  \n",
       "25%    136282.020139  \n",
       "50%    175159.233333  \n",
       "75%    213897.000000  \n",
       "max    429208.138889  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The predictions then form the training samples for an L2 model as an ensemble.\n",
    "l2_train=pd.DataFrame()\n",
    "l2_test=pd.DataFrame()\n",
    "for i in range(10):\n",
    "    clf_names=['rf_auto_'+str(i),'rf_manual_'+str(i),'ad_linear_'+str(i),'ad_sqr_'+str(i),'ad_exp_'+str(i),'et_'+str(i)] # find regressors by name\n",
    "    print \"This batch contains: \",clf_names\n",
    "    for clf_name in clf_names:\n",
    "        clf=regressors[clf_name]\n",
    "            \n",
    "        # Train\n",
    "        this_y=clf.predict(X_train)\n",
    "        l2_train[clf_name]=this_y\n",
    "        \n",
    "        # Test\n",
    "        this_y_cv=clf.predict(X_test)\n",
    "        l2_test[clf_name]=this_y_cv\n",
    "        \n",
    "    print \"End of iteration \",i\n",
    "\n",
    "# Append the target\n",
    "# l2_train['SalePrice']=y_train\n",
    "# l2_test['SalePrice']=y_test\n",
    "\n",
    "l2_train.describe()\n",
    "l2_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR RMSE score: 0.118165207204\n"
     ]
    }
   ],
   "source": [
    "# Ensemble method 1: Logistic regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "l2_lr=LinearRegression()\n",
    "l2_lr.fit(l2_train,y_train)\n",
    "l2_lr_pred=l2_lr.predict(l2_test)\n",
    "print('LR RMSE score: {score}'.format(score=rmse_log_error(y_test, l2_lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load target data to predict\n",
    "base_path='D:/kaggle/regression/'\n",
    "target_data=DataFrame.from_csv(base_path+'cleaned_test.csv',index_col='Id')\n",
    "target_data=target_data.drop(['SalePrice'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This batch contains:  ['rf_auto_0', 'rf_manual_0', 'ad_linear_0', 'ad_sqr_0', 'ad_exp_0', 'et_0']\n",
      "End of iteration  0\n",
      "This batch contains:  ['rf_auto_1', 'rf_manual_1', 'ad_linear_1', 'ad_sqr_1', 'ad_exp_1', 'et_1']\n",
      "End of iteration  1\n",
      "This batch contains:  ['rf_auto_2', 'rf_manual_2', 'ad_linear_2', 'ad_sqr_2', 'ad_exp_2', 'et_2']\n",
      "End of iteration  2\n",
      "This batch contains:  ['rf_auto_3', 'rf_manual_3', 'ad_linear_3', 'ad_sqr_3', 'ad_exp_3', 'et_3']\n",
      "End of iteration  3\n",
      "This batch contains:  ['rf_auto_4', 'rf_manual_4', 'ad_linear_4', 'ad_sqr_4', 'ad_exp_4', 'et_4']\n",
      "End of iteration  4\n",
      "This batch contains:  ['rf_auto_5', 'rf_manual_5', 'ad_linear_5', 'ad_sqr_5', 'ad_exp_5', 'et_5']\n",
      "End of iteration  5\n",
      "This batch contains:  ['rf_auto_6', 'rf_manual_6', 'ad_linear_6', 'ad_sqr_6', 'ad_exp_6', 'et_6']\n",
      "End of iteration  6\n",
      "This batch contains:  ['rf_auto_7', 'rf_manual_7', 'ad_linear_7', 'ad_sqr_7', 'ad_exp_7', 'et_7']\n",
      "End of iteration  7\n",
      "This batch contains:  ['rf_auto_8', 'rf_manual_8', 'ad_linear_8', 'ad_sqr_8', 'ad_exp_8', 'et_8']\n",
      "End of iteration  8\n",
      "This batch contains:  ['rf_auto_9', 'rf_manual_9', 'ad_linear_9', 'ad_sqr_9', 'ad_exp_9', 'et_9']\n",
      "End of iteration  9\n"
     ]
    }
   ],
   "source": [
    "# Generate L2 for test\n",
    "l2_target=pd.DataFrame()\n",
    "for i in range(10):\n",
    "    clf_names=['rf_auto_'+str(i),'rf_manual_'+str(i),'ad_linear_'+str(i),'ad_sqr_'+str(i),'ad_exp_'+str(i),'et_'+str(i)] # find regressors by name\n",
    "    print \"This batch contains: \",clf_names\n",
    "    for clf_name in clf_names:\n",
    "        clf=regressors[clf_name]\n",
    "        \n",
    "        this_y=clf.predict(target_data)\n",
    "        l2_target[clf_name]=this_y\n",
    "        \n",
    "    print \"End of iteration \",i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1459.000000\n",
       "mean     179012.990105\n",
       "std       69995.144681\n",
       "min       51274.558471\n",
       "25%      130919.936175\n",
       "50%      160126.587229\n",
       "75%      208582.195514\n",
       "max      497846.869298\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with L2 LR\n",
    "target_y=l2_lr.predict(l2_target)\n",
    "\n",
    "# Inspect\n",
    "y_df=pd.Series(target_y)\n",
    "y_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470,\n",
       "            ...\n",
       "            2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919],\n",
       "           dtype='int64', name=u'Id', length=1459)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output\n",
    "y_df.index=target_data.index\n",
    "y_df.to_csv(base_path+'target_handtuned_10rounds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune LR not used\n",
    "\n",
    "print \"Linear regression L2 tuning\"\n",
    "params={\n",
    "    'n_estimators':[42,43,44],\n",
    "    'max_features':[0.0002,0.0003,0.0004],\n",
    "    'max_depth':[1]\n",
    "        }\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "rfc = RandomForestRegressor(criterion='mse', n_jobs=-1)\n",
    "gs = GridSearchCV(rfc, params,cv=5,verbose=2)\n",
    "gs.fit(X_train, y_train)\n",
    "print 'Report scores'\n",
    "print gs.grid_scores_\n",
    "print(\"Report best params for random forest\")\n",
    "best_parameters, score, _ = min(gs.grid_scores_, key=lambda x: x[1])\n",
    "reportParams(best_parameters, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
